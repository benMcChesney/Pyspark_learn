{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Load MySQL Table and Write as Delta\") \\\n",
    "    .getOrCreate()\n",
    "#     .config(\"spark.jars\", \"/path/to/mysql-connector-java.jar\") \\\n",
    "spark.sparkContext.setJobDescription(\"delta job\")\n",
    "\"\"\"\n",
    "\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "builder = (\n",
    "        SparkSession.builder\n",
    "        .appName(\"pytest-pyspark-local-testing\")\n",
    "        .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "        .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.add_packages('mysql:mysql-connector-java:9.2.0')\n",
    "print( spark.version )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|age|      name|\n",
      "+---+----------+\n",
      "| 30|John    D.|\n",
      "| 25|Alice   G.|\n",
      "| 35|   Bob  T.|\n",
      "| 28|  Eve   A.|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data = [{\"name\": \"John    D.\", \"age\": 30},\n",
    "  {\"name\": \"Alice   G.\", \"age\": 25},\n",
    "  {\"name\": \"Bob  T.\", \"age\": 35},\n",
    "  {\"name\": \"Eve   A.\", \"age\": 28}]\n",
    "\n",
    "df = spark.createDataFrame(sample_data)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ini\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "# Create a ConfigParser object\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the .ini file\n",
    "config.read('settings.ini')  # Replace with the path to your .ini file\n",
    "# Accessing data from the .ini file\n",
    "username = config['settings']['username']\n",
    "password = config['settings']['password']\n",
    "host = config['settings']['host']\n",
    "port = config['settings']['port']\n",
    "schema = config['database']['schema']\n",
    "print('loaded ini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jdbc:mysql://localhost:3306/datastaging\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "| id|year|month|day|dep_time|sched_dep_time|dep_delay|arr_time|sched_arr_time|arr_delay|carrier|flight|tailnum|origin|dest|air_time|distance|hour|minute|          time_hour|                name|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "|  0|2013|    1|  1|   517.0|           515|      2.0|   830.0|           819|     11.0|     UA|  1545| N14228|   EWR| IAH|   227.0|    1400|   5|    15|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  1|2013|    1|  1|   533.0|           529|      4.0|   850.0|           830|     20.0|     UA|  1714| N24211|   LGA| IAH|   227.0|    1416|   5|    29|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  2|2013|    1|  1|   542.0|           540|      2.0|   923.0|           850|     33.0|     AA|  1141| N619AA|   JFK| MIA|   160.0|    1089|   5|    40|2013-01-01 05:00:00|American Airlines...|\n",
      "|  3|2013|    1|  1|   544.0|           545|     -1.0|  1004.0|          1022|    -18.0|     B6|   725| N804JB|   JFK| BQN|   183.0|    1576|   5|    45|2013-01-01 05:00:00|     JetBlue Airways|\n",
      "|  4|2013|    1|  1|   554.0|           600|     -6.0|   812.0|           837|    -25.0|     DL|   461| N668DN|   LGA| ATL|   116.0|     762|   6|     0|2013-01-01 06:00:00|Delta Air Lines Inc.|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the MySQL connection properties\n",
    "url = f\"jdbc:mysql://{host}:{port}/{schema}\"  # Replace with your MySQL server details\n",
    "print( url ) \n",
    "properties = {\n",
    "    \"user\": username,  # Replace with your MySQL username\n",
    "    \"password\": password,  # Replace with your MySQL password\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"  # MySQL JDBC driver\n",
    "}\n",
    "\n",
    "\n",
    "# Load data from MySQL table into a PySpark DataFrame\n",
    "df = spark.read.jdbc(url=url, table=\"flights\", properties=properties)\n",
    "\n",
    "# Show the data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path where the Delta table will be saved\n",
    "delta_path = \"data/flights/\" # Replace with your desired Delta table path\n",
    "\n",
    "# Save the DataFrame as a Delta table\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "| id|year|month|day|dep_time|sched_dep_time|dep_delay|arr_time|sched_arr_time|arr_delay|carrier|flight|tailnum|origin|dest|air_time|distance|hour|minute|          time_hour|                name|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "|  0|2013|    1|  1|   517.0|           515|      2.0|   830.0|           819|     11.0|     UA|  1545| N14228|   EWR| IAH|   227.0|    1400|   5|    15|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  1|2013|    1|  1|   533.0|           529|      4.0|   850.0|           830|     20.0|     UA|  1714| N24211|   LGA| IAH|   227.0|    1416|   5|    29|2013-01-01 05:00:00|United Air Lines ...|\n",
      "|  2|2013|    1|  1|   542.0|           540|      2.0|   923.0|           850|     33.0|     AA|  1141| N619AA|   JFK| MIA|   160.0|    1089|   5|    40|2013-01-01 05:00:00|American Airlines...|\n",
      "|  3|2013|    1|  1|   544.0|           545|     -1.0|  1004.0|          1022|    -18.0|     B6|   725| N804JB|   JFK| BQN|   183.0|    1576|   5|    45|2013-01-01 05:00:00|     JetBlue Airways|\n",
      "|  4|2013|    1|  1|   554.0|           600|     -6.0|   812.0|           837|    -25.0|     DL|   461| N668DN|   LGA| ATL|   116.0|     762|   6|     0|2013-01-01 06:00:00|Delta Air Lines Inc.|\n",
      "+---+----+-----+---+--------+--------------+---------+--------+--------------+---------+-------+------+-------+------+----+--------+--------+----+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data from the MySQL table into a PySpark DataFrame\n",
    "df = spark.read.jdbc(url=url, table=\"flights\", properties=properties)\n",
    "\n",
    "# Register the DataFrame as a temporary view\n",
    "df.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "# Show the result of the SQL query\n",
    "df.show(5)\n",
    "query_sql = \"SELECT * FROM flights WHERE month = 1\"\n",
    "result_df = spark.sql(query_sql)\n",
    "\n",
    "# Define the path where the Delta table will be saved\n",
    "delta_path = \"data/flights_merge/\" # Replace with your desired Delta table path\n",
    "\n",
    "# Save the DataFrame as a Delta table\n",
    "result_df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_sql = \"SELECT count(*) FROM flights WHERE month = 1\"\n",
    "result_df = spark.sql(query_sql)\n",
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
